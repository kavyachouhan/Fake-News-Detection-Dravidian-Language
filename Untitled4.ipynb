{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpINVz2r1Tmu",
        "outputId": "76b5fba3-55b9-4cf0-83fd-2615fc004bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.90      0.91       279\n",
            "         1.0       0.23      0.29      0.25        28\n",
            "\n",
            "    accuracy                           0.85       307\n",
            "   macro avg       0.58      0.59      0.58       307\n",
            "weighted avg       0.86      0.85      0.85       307\n",
            "\n",
            "[[252  27]\n",
            " [ 20   8]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Load the data\n",
        "data = pd.read_csv('labelled_train_set.csv')\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Drop any rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Convert text to lowercase\n",
        "data['News/Comment'] = data['News/Comment'].str.lower()\n",
        "\n",
        "# Encode the target variable\n",
        "data['Type'] = data['Type'].map({'FALSE': 0, 'HALF TRUE': 1, 'TRUE': 2})\n",
        "\n",
        "# Step 3: Split the data into features and target\n",
        "X = data['News/Comment']\n",
        "y = data['Type']\n",
        "\n",
        "# Handle Missing Values in Target Variable\n",
        "y = y.fillna(y.mode()[0]) # Fill missing values with the most frequent class\n",
        "\n",
        "# Step 4: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 5: Vectorize the text data\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 6: Handle class imbalance using SMOTE\n",
        "smote = SMOTE()\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_vectorized, y_train)\n",
        "\n",
        "# Step 7: Train the model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Step 8: Evaluate the model\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Print classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Optional: Save the model and vectorizer for future use\n",
        "import joblib\n",
        "joblib.dump(model, 'fake_news_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Step 1: Load the saved model and vectorizer\n",
        "model = joblib.load('fake_news_model.pkl')\n",
        "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "\n",
        "# Step 2: Load the new test data\n",
        "test_data = pd.read_csv('unlabelled_test1.csv')  # Replace with your test data file path\n",
        "\n",
        "# Step 3: Preprocess the test data\n",
        "# Convert text to lowercase\n",
        "test_data['News/Comment'] = test_data['News/Comment'].str.lower()\n",
        "\n",
        "# Step 4: Vectorize the test data\n",
        "X_test_vectorized = vectorizer.transform(test_data['News/Comment'])\n",
        "\n",
        "# Step 5: Make predictions\n",
        "predictions = model.predict(X_test_vectorized)\n",
        "\n",
        "# Step 6: Add predictions to the test data\n",
        "test_data['Predicted_Type'] = predictions\n",
        "\n",
        "# Step 7: Save the results\n",
        "test_data.to_csv('predicted_test_results.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predicted_test_results.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7NEmoZ-4IUQ",
        "outputId": "3aee43b9-4979-42b6-abde-edb5e34a900c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predicted_test_results.csv'\n"
          ]
        }
      ]
    }
  ]
}